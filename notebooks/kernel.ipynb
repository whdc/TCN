{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "710ed17d0c57bd287be0ee3b2782a53a54510561"
   },
   "source": [
    "## Summary\n",
    "\n",
    "- This Kernel is based on the third place winning single model by Alexander for the Toxic Comment Classification Challenge. Thought of porting the model to Pytorch for experimentation. \n",
    "- Also included is a Pytorch training loop for easy training of models and getting OOF predictions.\n",
    "- Included Debug Functionality - Was flustered with Kernels as they die if left for long time. Included the debug flag to handle such things better. Makes experimentation easier.\n",
    "\n",
    "Also Check ou my blog post at: https://mlwhiz.com/blog/2019/01/06/pytorch_keras_conversion/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "97b92845b85f289ba795c8c8f7117526abe073d0"
   },
   "source": [
    "## IMPORTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "abb7e3c30b8a412a50c6b451c49939e3cf4bc11b",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import re\n",
    "import torch\n",
    "from torchtext import data\n",
    "#import spacy\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas(desc='Progress')\n",
    "from collections import Counter\n",
    "from textblob import TextBlob\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "from torchtext.data import Example\n",
    "from sklearn.metrics import f1_score\n",
    "import torchtext\n",
    "import os \n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# cross validation and metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from unidecode import unidecode\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from textblob import TextBlob\n",
    "from multiprocessing import  Pool\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base = \"../quora-data/\"\n",
    "train_path = data_base + \"train.csv\"\n",
    "test_path = data_base + \"test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9a4ff5590a6f152dc1bec5aeca79aef10218f7de"
   },
   "source": [
    "### Basic Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "deee49df5ca1c4413f71677939e26aa1ff784e44",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 120000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 70 # max number of words in a question to use\n",
    "batch_size = 512 # how many samples to process at once\n",
    "n_epochs = 5 # how many times to iterate over all samples\n",
    "n_splits = 5 # Number of K-fold Splits\n",
    "SEED = 10\n",
    "debug =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "b53b0ebd37575ab31361099f0538cbb0457db5b6"
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCEWithLogitsLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "654cbe3c8a1f2a618a2441afe00df3b4a89e0a58"
   },
   "source": [
    "### Ensure determinism in the results\n",
    "\n",
    "A common headache in this competition is the lack of determinism in the results due to cudnn. The following Kernel has a solution in Pytorch.\n",
    "\n",
    "See https://www.kaggle.com/hengzheng/pytorch-starter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "58bbf87335799247586aaed16531f4d28d10ed4a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=10):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c890692644acce2dc4f6e2f929d6d294faca4ad2"
   },
   "source": [
    "### Code for Loading Embeddings\n",
    "\n",
    "Functions taken from the kernel:https://www.kaggle.com/gmhost/gru-capsule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "7026ee1d913f54dd4b560f654efdb9f833581cd3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## FUNCTIONS TAKEN FROM https://www.kaggle.com/gmhost/gru-capsule\n",
    "\n",
    "def load_glove(word_index):\n",
    "    EMBEDDING_FILE = data_base + 'embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')[:300]\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "    \n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = -0.005838499,0.48782197\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        #ALLmight\n",
    "        if embedding_vector is not None: \n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            embedding_vector = embeddings_index.get(word.capitalize())\n",
    "            if embedding_vector is not None: \n",
    "                embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix \n",
    "    \n",
    "            \n",
    "def load_fasttext(word_index):    \n",
    "    EMBEDDING_FILE = data_base + 'embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100)\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    return embedding_matrix\n",
    "\n",
    "def load_para(word_index):\n",
    "    EMBEDDING_FILE = data_base + 'embeddings/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, encoding=\"utf8\", errors='ignore') if len(o)>100)\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = -0.0053247833,0.49346462\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "07e9890ec0b490cef57565f7dff953aa56ebd3dc"
   },
   "source": [
    "## Normalization\n",
    "\n",
    "Borrowed from:\n",
    "* How to: Preprocessing when using embeddings\n",
    "https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings\n",
    "* Improve your Score with some Text Preprocessing https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "28ebb28ba78972bb8d4fee9b53437045542d20fb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_vocab(texts):\n",
    "    sentences = texts.apply(lambda x: x.split()).values\n",
    "    vocab = {}\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab\n",
    "\n",
    "def known_contractions(embed):\n",
    "    known = []\n",
    "    for contract in contraction_mapping:\n",
    "        if contract in embed:\n",
    "            known.append(contract)\n",
    "    return known\n",
    "\n",
    "def clean_contractions(text, mapping):\n",
    "    specials = [\"’\", \"‘\", \"´\", \"`\"]\n",
    "    for s in specials:\n",
    "        text = text.replace(s, \"'\")\n",
    "    text = ' '.join([mapping[t] if t in mapping else t for t in text.split(\" \")])\n",
    "    return text\n",
    "\n",
    "def correct_spelling(x, dic):\n",
    "    for word in dic.keys():\n",
    "        x = x.replace(word, dic[word])\n",
    "    return x\n",
    "\n",
    "def unknown_punct(embed, punct):\n",
    "    unknown = ''\n",
    "    for p in punct:\n",
    "        if p not in embed:\n",
    "            unknown += p\n",
    "            unknown += ' '\n",
    "    return unknown\n",
    "\n",
    "def clean_special_chars(text, punct, mapping):\n",
    "    for p in mapping:\n",
    "        text = text.replace(p, mapping[p])\n",
    "    \n",
    "    for p in punct:\n",
    "        text = text.replace(p, f' {p} ')\n",
    "    \n",
    "    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}  # Other special characters that I have to deal with in last\n",
    "    for s in specials:\n",
    "        text = text.replace(s, specials[s])\n",
    "    \n",
    "    return text\n",
    "\n",
    "def add_lower(embedding, vocab):\n",
    "    count = 0\n",
    "    for word in vocab:\n",
    "        if word in embedding and word.lower() not in embedding:\n",
    "            embedding[word.lower()] = embedding[word]\n",
    "            count += 1\n",
    "    print(f\"Added {count} words to embedding\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "abeab4c80d6829cf2eae706bfa7929e2871af81f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    for punct in puncts:\n",
    "        if punct in x:\n",
    "            x = x.replace(punct, f' {punct} ')\n",
    "    return x\n",
    "\n",
    "\n",
    "def clean_numbers(x):\n",
    "    if bool(re.search(r'\\d', x)):\n",
    "        x = re.sub('[0-9]{5,}', '#####', x)\n",
    "        x = re.sub('[0-9]{4}', '####', x)\n",
    "        x = re.sub('[0-9]{3}', '###', x)\n",
    "        x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x\n",
    "\n",
    "mispell_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", 'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', 'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization', 'demonetisation': 'demonetization'}\n",
    "\n",
    "def _get_mispell(mispell_dict):\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    return mispell_dict, mispell_re\n",
    "\n",
    "mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
    "def replace_typical_misspell(text):\n",
    "    def replace(match):\n",
    "        return mispellings[match.group(0)]\n",
    "    return mispellings_re.sub(replace, text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3c09d981ae674e6a373189a04dba8d0932b0765b"
   },
   "source": [
    "Extra feature part taken from https://github.com/wongchunghang/toxic-comment-challenge-lstm/blob/master/toxic_comment_9872_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "63cb21525251b060aeb309e7be4b48772f8720f5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def parallelize_apply(df,func,colname,num_process,newcolnames):\n",
    "    # takes as input a df and a function for one of the columns in df\n",
    "    pool =Pool(processes=num_process)\n",
    "    arraydata = pool.map(func,tqdm(df[colname].values))\n",
    "    pool.close()\n",
    "    \n",
    "    newdf = pd.DataFrame(arraydata,columns = newcolnames)\n",
    "    df = pd.concat([df,newdf],axis=1)\n",
    "    return df\n",
    "\n",
    "def parallelize_dataframe(df, func):\n",
    "    df_split = np.array_split(df, 4)\n",
    "    pool = Pool(4)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df\n",
    "\n",
    "def count_regexp_occ(regexp=\"\", text=None):\n",
    "    \"\"\" Simple way to get the number of occurence of a regex\"\"\"\n",
    "    return len(re.findall(regexp, text))\n",
    "\n",
    "\n",
    "# some fetures \n",
    "# ['','','india/n','','quora','','sex','','','country/countries','china','','','chinese','','']\n",
    "def add_features(df):\n",
    "    df['question_text'] = df['question_text'].progress_apply(lambda x:str(x))\n",
    "    df[\"lower_question_text\"] = df[\"question_text\"].apply(lambda x: x.lower())\n",
    "    # df = parallelize_apply(df,sentiment,'question_text',4,['sentiment','subjectivity']) \n",
    "    # df['sentiment'] = df['question_text'].progress_apply(lambda x:sentiment(x))\n",
    "    df['total_length'] = df['question_text'].progress_apply(len)\n",
    "    df['capitals'] = df['question_text'].progress_apply(lambda comment: sum(1 for c in comment if c.isupper()))\n",
    "    df['caps_vs_length'] = df.progress_apply(lambda row: float(row['capitals'])/float(row['total_length']),\n",
    "                                axis=1)\n",
    "    df['num_words'] = df.question_text.str.count('\\S+')\n",
    "    df['num_unique_words'] = df['question_text'].progress_apply(lambda comment: len(set(w for w in comment.split())))\n",
    "    df['words_vs_unique'] = df['num_unique_words'] / df['num_words'] \n",
    "    return df\n",
    "\n",
    "def load_and_prec():\n",
    "    if debug:\n",
    "        train_df = pd.read_csv(train_path)[:80000]\n",
    "        test_df = pd.read_csv(test_path)[:20000]\n",
    "    else:\n",
    "        train_df = pd.read_csv(train_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "    print(\"Train shape : \",train_df.shape)\n",
    "    print(\"Test shape : \",test_df.shape)\n",
    "    \n",
    "    ###################### Add Features ###############################\n",
    "    #  https://github.com/wongchunghang/toxic-comment-challenge-lstm/blob/master/toxic_comment_9872_model.ipynb\n",
    "    '''\n",
    "    train = add_features(train_df)\n",
    "    test = add_features(test_df)\n",
    "    '''\n",
    "    \n",
    "    train = parallelize_dataframe(train_df, add_features)\n",
    "    test = parallelize_dataframe(test_df, add_features)\n",
    "    \n",
    "    # lower\n",
    "    train_df[\"question_text\"] = train_df[\"question_text\"].apply(lambda x: x.lower())\n",
    "    test_df[\"question_text\"] = test_df[\"question_text\"].apply(lambda x: x.lower())\n",
    "\n",
    "    # Clean the text\n",
    "    train_df[\"question_text\"] = train_df[\"question_text\"].progress_apply(lambda x: clean_text(x))\n",
    "    test_df[\"question_text\"] = test_df[\"question_text\"].apply(lambda x: clean_text(x))\n",
    "    \n",
    "    # Clean numbers\n",
    "    train_df[\"question_text\"] = train_df[\"question_text\"].progress_apply(lambda x: clean_numbers(x))\n",
    "    test_df[\"question_text\"] = test_df[\"question_text\"].apply(lambda x: clean_numbers(x))\n",
    "    \n",
    "    # Clean speelings\n",
    "    train_df[\"question_text\"] = train_df[\"question_text\"].progress_apply(lambda x: replace_typical_misspell(x))\n",
    "    test_df[\"question_text\"] = test_df[\"question_text\"].apply(lambda x: replace_typical_misspell(x))\n",
    "    \n",
    "    ## fill up the missing values\n",
    "    train_X = train_df[\"question_text\"].fillna(\"_##_\").values\n",
    "    test_X = test_df[\"question_text\"].fillna(\"_##_\").values\n",
    "\n",
    "\n",
    "    \n",
    "    features = train[['num_unique_words','words_vs_unique']].fillna(0)\n",
    "    test_features = test[['num_unique_words','words_vs_unique']].fillna(0)\n",
    "    \n",
    "    # doing PCA to reduce network run times\n",
    "    ss = StandardScaler()\n",
    "    pc = PCA(n_components=5)\n",
    "    ss.fit(np.vstack((features, test_features)))\n",
    "    features = ss.transform(features)\n",
    "    test_features = ss.transform(test_features)\n",
    "    \n",
    "    ###########################################################################\n",
    "\n",
    "    ## Tokenize the sentences\n",
    "    tokenizer = Tokenizer(num_words=max_features)\n",
    "    tokenizer.fit_on_texts(list(train_X))\n",
    "    train_X = tokenizer.texts_to_sequences(train_X)\n",
    "    test_X = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "    ## Pad the sentences \n",
    "    train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "    test_X = pad_sequences(test_X, maxlen=maxlen)\n",
    "\n",
    "    ## Get the target values\n",
    "    train_y = train_df['target'].values\n",
    "    \n",
    "#     # Splitting to training and a final test set    \n",
    "#     train_X, x_test_f, train_y, y_test_f = train_test_split(list(zip(train_X,features)), train_y, test_size=0.2, random_state=SEED)    \n",
    "#     train_X, features = zip(*train_X)\n",
    "#     x_test_f, features_t = zip(*x_test_f)    \n",
    "    \n",
    "    #shuffling the data\n",
    " \n",
    "    np.random.seed(SEED)\n",
    "    trn_idx = np.random.permutation(len(train_X))\n",
    "\n",
    "    train_X = train_X[trn_idx]\n",
    "    train_y = train_y[trn_idx]\n",
    "    features = features[trn_idx]\n",
    "    \n",
    "    return train_X, test_X, train_y, features, test_features, tokenizer.word_index\n",
    "#     return train_X, test_X, train_y, x_test_f,y_test_f,features, test_features, features_t, tokenizer.word_index\n",
    "#     return train_X, test_X, train_y, tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "3c72fcddb4f680879e231c3dbfc0c71e27fc424c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1306122, 3)\n",
      "Test shape :  (56370, 2)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b915a64dec41443f967347c4bf2fe1d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=326531, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77852bc773de465ba475673c158cd767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=326531, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8559d25046417992577e04e5c207cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=326530, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dedbf51c7c34e12adba1139f51602c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=326531, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d46041187e4260b932a420dee8fa6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=326530, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a9273e234045b0b3597381442d3f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=326531, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf56d46dee84fa29662e92fd973a885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=326530, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80276900b1fa418a8c83972027da36f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=326530, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b17673ee074f21b5349f3d280e4620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=326531, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a553fb16492434699399e0512f834d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=326531, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39f31c36a644eb9bd2c90b96b7aa390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=326530, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23581b788478485ca2c0e8e65e260d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=326530, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7862f1c5803849e0885c6e91199653de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=326531, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f080901fd3d3438e8d181f9a042f5a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=326531, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6952fdd0f849ddaafd7901b224feb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=326530, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcab6e48b5e404ab47159c11ef9c2e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=326530, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6f0a8daa474af99e729eb28cf4f4f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=14093, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e9e1923fa54355bc3fe175977e731a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=14092, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d6fa2144774b6ea9f6195f0323720b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=14093, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3763d7a9d84060b48a47258a0a180f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=14092, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f54af470e7e4f999ca8088d86f7a2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=14093, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520dec04d352428e9a6b58722fd00d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=14092, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630e697e737643ba8d131bc11126382f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=14093, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a4faccb015e44659745017da2e6506b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=14092, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533b81e216c449e4a9b4bc92925d26a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=14093, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7fe68fd9a794cbe9d884096756c5d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=14092, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d42a57576e4ef38923b474a0bd1d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=14093, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a54ca47884c4bf98e05e1d13cab8975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=14092, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e456e5cfdc1d41a381063090c2703fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=14093, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db97d0cca79642f39b016d110acd5b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=14092, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bfad7c1a82f464e9498762ebb230854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=14093, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b942544ceaca4832aed8f65fdeb37775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=14092, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c325351f2d104269820d794eac58cc03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=1306122, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437a97e5c5124e1e86ad9f43f56b7db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=1306122, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81e6cb1380f480487abfc180ee6b7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Progress', max=1306122, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sj/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:89: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "/home/sj/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:90: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101.09598755836487\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# fill up the missing values\n",
    "# x_train, x_test, y_train, word_index = load_and_prec()\n",
    "x_train, x_test, y_train, features, test_features, word_index = load_and_prec() \n",
    "# x_train, x_test, y_train, x_test_f,y_test_f,features, test_features,features_t, word_index = load_and_prec() \n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e5c51a8329d569d13b9f0369ebb98ca8e2e55440"
   },
   "source": [
    "### Load Embeddings\n",
    "\n",
    "Changing method: first load index and then load embedding\n",
    "Two embedding matrices have been used. Glove, and paragram. The mean of the two is used as the final embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "6a5f4502324d369ff6faa3692accee4f8a233005",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# missing entries in the embedding are set using np.random.normal so we have to seed here too\n",
    "seed_everything()\n",
    "if debug:\n",
    "    paragram_embeddings = np.random.randn(120000,300)\n",
    "    glove_embeddings = np.random.randn(120000,300)\n",
    "    embedding_matrix = np.mean([glove_embeddings, paragram_embeddings], axis=0)\n",
    "else:\n",
    "    glove_embeddings = load_glove(word_index)    \n",
    "    paragram_embeddings = load_para(word_index)\n",
    "    embedding_matrix = np.mean([glove_embeddings, paragram_embeddings], axis=0)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "aa6a41607b804d76a2ddc530c912b5673bcd2423"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8098bea0cee9117ff9dc4e11feba53e49b80cb55"
   },
   "source": [
    "### Cyclic CLR\n",
    "Code taken from https://www.kaggle.com/dannykliu/lstm-with-attention-clr-in-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "9d531a7454923f90d0e7443b1ed1373d008c2e88",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# code inspired from: https://github.com/anandsaha/pytorch.cyclic.learning.rate/blob/master/cls.py\n",
    "class CyclicLR(object):\n",
    "    def __init__(self, optimizer, base_lr=1e-3, max_lr=6e-3,\n",
    "                 step_size=2000, mode='triangular', gamma=1.,\n",
    "                 scale_fn=None, scale_mode='cycle', last_batch_iteration=-1):\n",
    "\n",
    "        if not isinstance(optimizer, Optimizer):\n",
    "            raise TypeError('{} is not an Optimizer'.format(\n",
    "                type(optimizer).__name__))\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        if isinstance(base_lr, list) or isinstance(base_lr, tuple):\n",
    "            if len(base_lr) != len(optimizer.param_groups):\n",
    "                raise ValueError(\"expected {} base_lr, got {}\".format(\n",
    "                    len(optimizer.param_groups), len(base_lr)))\n",
    "            self.base_lrs = list(base_lr)\n",
    "        else:\n",
    "            self.base_lrs = [base_lr] * len(optimizer.param_groups)\n",
    "\n",
    "        if isinstance(max_lr, list) or isinstance(max_lr, tuple):\n",
    "            if len(max_lr) != len(optimizer.param_groups):\n",
    "                raise ValueError(\"expected {} max_lr, got {}\".format(\n",
    "                    len(optimizer.param_groups), len(max_lr)))\n",
    "            self.max_lrs = list(max_lr)\n",
    "        else:\n",
    "            self.max_lrs = [max_lr] * len(optimizer.param_groups)\n",
    "\n",
    "        self.step_size = step_size\n",
    "\n",
    "        if mode not in ['triangular', 'triangular2', 'exp_range'] \\\n",
    "                and scale_fn is None:\n",
    "            raise ValueError('mode is invalid and scale_fn is None')\n",
    "\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "\n",
    "        if scale_fn is None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = self._triangular_scale_fn\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = self._triangular2_scale_fn\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = self._exp_range_scale_fn\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "\n",
    "        self.batch_step(last_batch_iteration + 1)\n",
    "        self.last_batch_iteration = last_batch_iteration\n",
    "\n",
    "    def batch_step(self, batch_iteration=None):\n",
    "        if batch_iteration is None:\n",
    "            batch_iteration = self.last_batch_iteration + 1\n",
    "        self.last_batch_iteration = batch_iteration\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    def _triangular_scale_fn(self, x):\n",
    "        return 1.\n",
    "\n",
    "    def _triangular2_scale_fn(self, x):\n",
    "        return 1 / (2. ** (x - 1))\n",
    "\n",
    "    def _exp_range_scale_fn(self, x):\n",
    "        return self.gamma**(x)\n",
    "\n",
    "    def get_lr(self):\n",
    "        step_size = float(self.step_size)\n",
    "        cycle = np.floor(1 + self.last_batch_iteration / (2 * step_size))\n",
    "        x = np.abs(self.last_batch_iteration / step_size - 2 * cycle + 1)\n",
    "\n",
    "        lrs = []\n",
    "        param_lrs = zip(self.optimizer.param_groups, self.base_lrs, self.max_lrs)\n",
    "        for param_group, base_lr, max_lr in param_lrs:\n",
    "            base_height = (max_lr - base_lr) * np.maximum(0, (1 - x))\n",
    "            if self.scale_mode == 'cycle':\n",
    "                lr = base_lr + base_height * self.scale_fn(cycle)\n",
    "            else:\n",
    "                lr = base_lr + base_height * self.scale_fn(self.last_batch_iteration)\n",
    "            lrs.append(lr)\n",
    "        return lrs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0da30e2afce23b753796f3045b44ce91a07e4303"
   },
   "source": [
    "### Pytorch Run Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "6a5afb54f70a29808af19946ba08ef971d194e46"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self,dataset):\n",
    "        self.dataset = dataset\n",
    "    def __getitem__(self,index):\n",
    "        data,target = self.dataset[index]\n",
    "        return data,target,index\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "b711f30cbb4b0297fec816b8102c477d9a546c80"
   },
   "outputs": [],
   "source": [
    "def pytorch_model_run_cv(x_train,y_train,features,x_test, model_obj, feats = False,clip = True):\n",
    "    seed_everything()\n",
    "    avg_losses_f = []\n",
    "    avg_val_losses_f = []\n",
    "    # matrix for the out-of-fold predictions\n",
    "    train_preds = np.zeros((len(x_train)))\n",
    "    # matrix for the predictions on the test set\n",
    "    test_preds = np.zeros((len(x_test)))\n",
    "    splits = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED).split(x_train, y_train))\n",
    "    for i, (train_idx, valid_idx) in enumerate(splits):\n",
    "        seed_everything(i*1000+i)\n",
    "        x_train = np.array(x_train)\n",
    "        y_train = np.array(y_train)\n",
    "        if feats:\n",
    "            features = np.array(features)\n",
    "        x_train_fold = torch.tensor(x_train[train_idx.astype(int)], dtype=torch.long).cuda()\n",
    "        y_train_fold = torch.tensor(y_train[train_idx.astype(int), np.newaxis], dtype=torch.float32).cuda()\n",
    "        if feats:\n",
    "            kfold_X_features = features[train_idx.astype(int)]\n",
    "            kfold_X_valid_features = features[valid_idx.astype(int)]\n",
    "        x_val_fold = torch.tensor(x_train[valid_idx.astype(int)], dtype=torch.long).cuda()\n",
    "        y_val_fold = torch.tensor(y_train[valid_idx.astype(int), np.newaxis], dtype=torch.float32).cuda()\n",
    "        \n",
    "        model = copy.deepcopy(model_obj)\n",
    "\n",
    "        model.cuda()\n",
    "\n",
    "        loss_fn = torch.nn.BCEWithLogitsLoss(reduction='sum')\n",
    "\n",
    "        step_size = 300\n",
    "        base_lr, max_lr = 0.001, 0.003   \n",
    "        optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), \n",
    "                                 lr=max_lr)\n",
    "        \n",
    "        ################################################################################################\n",
    "        scheduler = CyclicLR(optimizer, base_lr=base_lr, max_lr=max_lr,\n",
    "                   step_size=step_size, mode='exp_range',\n",
    "                   gamma=0.99994)\n",
    "        ###############################################################################################\n",
    "\n",
    "        train = MyDataset(torch.utils.data.TensorDataset(x_train_fold, y_train_fold))\n",
    "        valid = MyDataset(torch.utils.data.TensorDataset(x_val_fold, y_val_fold))\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "        valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        print(f'Fold {i + 1}')\n",
    "        for epoch in range(n_epochs):\n",
    "            start_time = time.time()\n",
    "            model.train()\n",
    "\n",
    "            avg_loss = 0.  \n",
    "            for i, (x_batch, y_batch, index) in enumerate(train_loader):\n",
    "                if feats:       \n",
    "                    f = kfold_X_features[index]\n",
    "                    y_pred = model([x_batch,f])\n",
    "                else:\n",
    "                    y_pred = model(x_batch)\n",
    "\n",
    "                if scheduler:\n",
    "                    scheduler.batch_step()\n",
    "\n",
    "                # Compute and print loss.\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                if clip:\n",
    "                    nn.utils.clip_grad_norm_(model.parameters(),1)\n",
    "                optimizer.step()\n",
    "                avg_loss += loss.item() / len(train_loader)\n",
    "                \n",
    "            model.eval()\n",
    "            \n",
    "            valid_preds_fold = np.zeros((x_val_fold.size(0)))\n",
    "            test_preds_fold = np.zeros((len(x_test)))\n",
    "            \n",
    "            avg_val_loss = 0.\n",
    "            for i, (x_batch, y_batch,index) in enumerate(valid_loader):\n",
    "                if feats:\n",
    "                    f = kfold_X_valid_features[index]            \n",
    "                    y_pred = model([x_batch,f]).detach()\n",
    "                else:\n",
    "                    y_pred = model(x_batch).detach()\n",
    "                \n",
    "                avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "                valid_preds_fold[index] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
    "            \n",
    "            elapsed_time = time.time() - start_time \n",
    "            print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t time={:.2f}s'.format(\n",
    "                epoch + 1, n_epochs, avg_loss, avg_val_loss, elapsed_time))\n",
    "        avg_losses_f.append(avg_loss)\n",
    "        avg_val_losses_f.append(avg_val_loss) \n",
    "        # predict all samples in the test set batch per batch\n",
    "        for i, (x_batch,) in enumerate(test_loader):\n",
    "            if feats:\n",
    "                f = test_features[i * batch_size:(i+1) * batch_size]\n",
    "                y_pred = model([x_batch,f]).detach()\n",
    "            else:\n",
    "                y_pred = model(x_batch).detach()\n",
    "\n",
    "            test_preds_fold[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
    "            \n",
    "        train_preds[valid_idx] = valid_preds_fold\n",
    "        test_preds += test_preds_fold / len(splits)\n",
    "\n",
    "    print('All \\t loss={:.4f} \\t val_loss={:.4f} \\t '.format(np.average(avg_losses_f),np.average(avg_val_losses_f)))\n",
    "    return train_preds, test_preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b8caecb207a12d4a5524fe16e4524b31c7da8bac"
   },
   "source": [
    "### Model\n",
    "\n",
    "Initial idea borrowed from: https://www.kaggle.com/ziliwang/baseline-pytorch-bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "26e90f1839b084c126414250eac1f636b0c88937"
   },
   "outputs": [],
   "source": [
    "# create Models:\n",
    "\n",
    "class Alex_NeuralNet_Meta(nn.Module):\n",
    "    def __init__(self,hidden_size,lin_size, embedding_matrix=embedding_matrix):\n",
    "        super(Alex_NeuralNet_Meta, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        drp = 0.1\n",
    "        self.embedding = nn.Embedding(max_features, embed_size)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "\n",
    "        self.embedding_dropout = nn.Dropout2d(0.1)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, bidirectional=True, batch_first=True)\n",
    "\n",
    "        for name, param in self.lstm.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                 nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                 nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                 nn.init.orthogonal_(param)\n",
    "\n",
    "        self.gru = nn.GRU(hidden_size*2, hidden_size, bidirectional=True, batch_first=True)\n",
    "\n",
    "        for name, param in self.gru.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                 nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                 nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                 nn.init.orthogonal_(param)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_size*6 + features.shape[1], lin_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(drp)\n",
    "        self.out = nn.Linear(lin_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_embedding = self.embedding(x[0])\n",
    "        h_embedding = torch.squeeze(self.embedding_dropout(torch.unsqueeze(h_embedding, 0)))\n",
    "        #print(\"emb\", h_embedding.size())\n",
    "        h_lstm, _ = self.lstm(h_embedding)\n",
    "        #print(\"lst\",h_lstm.size())\n",
    "        h_gru, hh_gru = self.gru(h_lstm)\n",
    "        hh_gru = hh_gru.view(-1, 2*self.hidden_size )\n",
    "        #print(\"gru\", h_gru.size())\n",
    "        #print(\"h_gru\", hh_gru.size())\n",
    "        avg_pool = torch.mean(h_gru, 1)\n",
    "        max_pool, _ = torch.max(h_gru, 1)\n",
    "        #print(\"avg_pool\", avg_pool.size())\n",
    "        #print(\"max_pool\", max_pool.size())\n",
    "        f = torch.tensor(x[1], dtype=torch.float).cuda()\n",
    "        #print(\"f\", f.size())\n",
    "        conc = torch.cat(( hh_gru, avg_pool, max_pool,f), 1)\n",
    "        #print(\"conc\", conc.size())\n",
    "        conc = self.relu(self.linear(conc))\n",
    "        conc = self.dropout(conc)\n",
    "        out = self.out(conc)\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "551ff8837a1b0899e0925c1a3801547adeddccae"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# always call this before training for deterministic results\n",
    "seed_everything()\n",
    "\n",
    "x_test_cuda = torch.tensor(x_test, dtype=torch.long).cuda()\n",
    "test = torch.utils.data.TensorDataset(x_test_cuda)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3b8f851d15f3e34d40eab4146393c145886b3966",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1/5 \t loss=65.9524 \t val_loss=52.9146 \t time=69.18s\n",
      "Epoch 2/5 \t loss=58.1200 \t val_loss=51.5925 \t time=69.19s\n",
      "Epoch 3/5 \t loss=54.8474 \t val_loss=50.7379 \t time=69.43s\n",
      "Epoch 4/5 \t loss=51.8081 \t val_loss=52.4340 \t time=69.73s\n",
      "Epoch 5/5 \t loss=48.5144 \t val_loss=52.7188 \t time=69.31s\n",
      "Fold 2\n",
      "Epoch 1/5 \t loss=66.0338 \t val_loss=54.5078 \t time=69.40s\n",
      "Epoch 2/5 \t loss=58.2274 \t val_loss=51.5742 \t time=69.74s\n",
      "Epoch 3/5 \t loss=54.4763 \t val_loss=51.4642 \t time=69.71s\n",
      "Epoch 4/5 \t loss=51.2804 \t val_loss=51.7638 \t time=69.69s\n",
      "Epoch 5/5 \t loss=48.1423 \t val_loss=52.1991 \t time=69.44s\n",
      "Fold 3\n"
     ]
    }
   ],
   "source": [
    "train_preds , test_preds = pytorch_model_run_cv(\n",
    "    x_train, y_train, features, x_test, Alex_NeuralNet_Meta(70, 16, embedding_matrix=embedding_matrix), feats = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "2191b67649a32a07387fb1ac0e05527020dd14b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.07582562e-01, 3.30806635e-02, 3.82245369e-02, ...,\n",
       "       7.35885942e-06, 1.07967425e-02, 3.22647757e-05])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "2ab6ac01d6d69d88ef05a542cb6f8e27cd23a8ab"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d1eff971704267966732c98b9d5d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=41), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best threshold is 0.3600 with F1 score: 0.6792\n"
     ]
    }
   ],
   "source": [
    "def bestThresshold(y_train,train_preds):\n",
    "    tmp = [0,0,0] # idx, cur, max\n",
    "    delta = 0\n",
    "    for tmp[0] in tqdm(np.arange(0.1, 0.501, 0.01)):\n",
    "        tmp[1] = f1_score(y_train, np.array(train_preds)>tmp[0])\n",
    "        if tmp[1] > tmp[2]:\n",
    "            delta = tmp[0]\n",
    "            tmp[2] = tmp[1]\n",
    "    print('best threshold is {:.4f} with F1 score: {:.4f}'.format(delta, tmp[2]))\n",
    "    return delta , tmp[2]\n",
    "\n",
    "delta, _ = bestThresshold(y_train,train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "d8bf091cac7ce485afc35bdcc50d3a9ea59f8e2a"
   },
   "outputs": [],
   "source": [
    "if debug:\n",
    "    df_test = pd.read_csv(test_path)[:20000]\n",
    "else:\n",
    "    df_test = pd.read_csv(test_path)\n",
    "submission = df_test[['qid']].copy()\n",
    "submission['prediction'] = (test_preds > delta).astype(int)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_uuid": "13dea8e1c900175db765f3fac41bcaec035d4476"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qid,prediction\r\n",
      "00014894849d00ba98a9,0\r\n",
      "000156468431f09b3cae,0\r\n",
      "000227734433360e1aae,0\r\n",
      "0005e06fbe3045bd2a92,0\r\n",
      "00068a0f7f41f50fc399,0\r\n",
      "000a2d30e3ffd70c070d,0\r\n",
      "000b67672ec9622ff761,0\r\n",
      "000b7fb1146d712c1105,0\r\n",
      "000d665a8ddc426a1907,0\r\n",
      "000df6fd2229447b2969,0\r\n",
      "000e8d4169c8dc7ab5ee,0\r\n",
      "000ef78071824e781d67,0\r\n",
      "001014ae8ebec25a597a,0\r\n",
      "0010236e0aa3ab39a282,0\r\n",
      "00105665c8ffd3c5852a,0\r\n",
      "00106ef7c87fca3b77a8,0\r\n",
      "001441e83b68c02c30da,0\r\n",
      "0014a461bd2a374f2eec,0\r\n",
      "0017148dde8e587c0f9c,0\r\n",
      "00175846ae0cfa2fc7d4,0\r\n",
      "0018d0ba9822bdb872b3,0\r\n",
      "001a492c2df37ba885d0,0\r\n",
      "001a52478cd34a11aee6,0\r\n",
      "001c132aa697402a00db,0\r\n",
      "001cb1f0c10c8e413418,0\r\n",
      "001e31e30a5762fa97fd,0\r\n",
      "001e50b789e8db63b7bb,0\r\n",
      "0021ef17b8d5a2cfa678,0\r\n",
      "00262cae7eb54e29dce7,0\r\n",
      "00277400ab4bae3246b0,0\r\n",
      "00287db03716e945d491,0\r\n",
      "002ae42c01ea0481a095,0\r\n",
      "002b1f3affefacd9d3ad,0\r\n",
      "002b9348a4907bb18f3e,0\r\n",
      "002c93ba07ab88d1bd93,0\r\n",
      "002cac1ac261e86fd770,0\r\n",
      "002cf96dede4f6182757,0\r\n",
      "002d1c5859e1d2db5f33,0\r\n",
      "002f7e0035c5c352e4c6,0\r\n",
      "003069ba70645b15c3ba,1\r\n",
      "0032e99a8b20fdf06fa3,0\r\n",
      "003422717ffe5e1cf403,0\r\n",
      "0036696fb9d739e9afbf,0\r\n",
      "0037508b02b395e6feed,0\r\n",
      "0037a73a9ecbd8920f91,0\r\n",
      "0037b011bddd6f330919,0\r\n",
      "0039457910b8a802121b,1\r\n",
      "00399c2236f28c3b6c72,0\r\n",
      "003a462692950cc4884b,0\r\n",
      "003cecd8c8afd2bd1ca0,0\r\n",
      "003da341bc2d578818b2,0\r\n",
      "003ec867b01fbc195a6f,0\r\n",
      "0042f074b81ab833982c,0\r\n",
      "0043c9a2eef81e694a12,0\r\n",
      "0045631c9addae05959e,0\r\n",
      "00477a2b35825d705e67,0\r\n",
      "00483acc724f52374664,0\r\n",
      "0048914230355aed33bd,0\r\n",
      "0048cfd72e6c0f434f5e,0\r\n",
      "004dabf418e017eaa810,0\r\n",
      "0050e4482f0e95bdb4d7,0\r\n",
      "00515115172cb2ccbd42,0\r\n",
      "005238b49b0b93460e4d,0\r\n",
      "00526a263a409fcb9a7b,0\r\n",
      "00538508b015ad240afb,0\r\n",
      "00543b92b168a6f86e3e,0\r\n",
      "0055976a08be122ca564,0\r\n",
      "0056b6e24336f08d8ea1,0\r\n",
      "0059a95549e24a31f746,0\r\n",
      "005af7396a84a515f67c,0\r\n",
      "005bdbd42f2a5f2359a9,0\r\n",
      "005c13e5dfa2abc82026,0\r\n",
      "005ca39f35e5e2723184,0\r\n",
      "005e66c0822365210735,0\r\n",
      "005ed837dbe46466085f,0\r\n",
      "005fdff4a2e6b2f81dd9,0\r\n",
      "00606077f6fe3bb93630,0\r\n",
      "0061c39bba71f03ac780,1\r\n",
      "0061fc56b4a1f27e802b,0\r\n",
      "00626bfb7fb79a1823bc,0\r\n",
      "00627daf7194fcf7cbad,0\r\n",
      "006428668c592a8d40e8,0\r\n",
      "00662dd4d61393e22f38,0\r\n",
      "00672e08658fc45175d0,0\r\n",
      "00679f1a45e588e1de0a,0\r\n",
      "0067b851693044216b69,0\r\n",
      "0069468befb619ce22c6,0\r\n",
      "006c57aece642d975e98,0\r\n",
      "006c793aefecfea732e1,0\r\n",
      "006e81e91e754b65c1f5,0\r\n",
      "0075302091236862234d,0\r\n",
      "0075eb835c256ac77872,0\r\n",
      "00772b748e996dee2147,0\r\n",
      "007aa59a40ef8defcca9,0\r\n",
      "007bcf30160dd4ff8095,0\r\n",
      "007bf4638195efc95d11,0\r\n",
      "007ca3c66488a9a8205c,0\r\n",
      "007dd2133411ac4de1d2,0\r\n",
      "007e65e4441890f4416b,1\r\n",
      "00826e978415f172d856,0\r\n",
      "008347d164d993397662,0\r\n",
      "00871f439753fa119962,0\r\n",
      "00888dc5bfb277276e36,1\r\n",
      "008ab32b66692c1b6b69,0\r\n",
      "008bc5fc80aa2c58a662,0\r\n",
      "008c09d908a175160cd2,1\r\n",
      "008d1e2f5e80fa131ea3,0\r\n",
      "008dbdc7d710efb68746,0\r\n",
      "008f1d1f3abb1b389a9d,0\r\n",
      "008fd545c1f9a7e6175e,0\r\n",
      "0090733f354250b59bc3,0\r\n",
      "00914f8020ca8495e229,0\r\n",
      "0094692c6c48fca65f46,1\r\n",
      "0096d249fb6077879ff6,0\r\n",
      "009a460333bdeea1cbba,0\r\n",
      "009aba4428fd320b58b9,0\r\n",
      "009ac334f67616a8368a,0\r\n",
      "009cf62985ead054a8ad,1\r\n",
      "009cffbc338b40e6d7f5,0\r\n",
      "009d3c4c9c5c3a2aac99,0\r\n",
      "009ec9a9b4d5126789a5,0\r\n",
      "00a03bc6744661752ecf,0\r\n",
      "00a13beb9ebc597d249c,0\r\n",
      "00a1de079178499e2baa,1\r\n",
      "00a2c49f9b658d78d9ea,0\r\n",
      "00a32b087dfb257485ac,0\r\n",
      "00a461154b1f9cad1300,0\r\n",
      "00a4f783da61c0bdc4d2,0\r\n",
      "00a7147b88070670b3b3,0\r\n",
      "00a71a2e7ea2e8d60c20,0\r\n",
      "00a78a779924cca6777f,0\r\n",
      "00ae44deeb4d7346fca7,0\r\n",
      "00aede95105f73f1e431,1\r\n",
      "00b11a9215a951baee20,0\r\n",
      "00b1937e743725fb5ea6,1\r\n",
      "00b3995bab75d42dc359,0\r\n",
      "00b4051f60ad6b1a1bde,0\r\n",
      "00b5032d146126a7c179,0\r\n",
      "00b6e1b625bbace886a5,0\r\n",
      "00b73d8f97f862044b8f,0\r\n",
      "00ba444f8182e93e334c,0\r\n",
      "00bae57779c0b7486ee1,0\r\n",
      "00bb4d4e84e6eb9a56a5,0\r\n",
      "00bcc4061a484529c306,0\r\n",
      "00bcd857965f1d0c9809,0\r\n",
      "00bda2d64d491120a821,0\r\n",
      "00bf7915b57809d34615,0\r\n",
      "00c0704cc8ab648ccaa0,0\r\n",
      "00c11db0acb0a57b6760,1\r\n",
      "00c37df6ac6c583da8f9,1\r\n",
      "00c52dc32ecfbc5cf491,0\r\n",
      "00c52e8dfc2c84c7b05f,0\r\n",
      "00c58f1512f41dd617ff,0\r\n",
      "00c660c58101eafe25e9,0\r\n",
      "00c8bd545afdec5dd3d4,0\r\n",
      "00c8f5242df163a79a3d,0\r\n",
      "00c97d83485289c8e9b0,0\r\n",
      "00ca60737d67218022e8,0\r\n",
      "00ca84836e0380d77149,0\r\n",
      "00cb0f28f402875aeecc,0\r\n",
      "00cb66c3a55fd9a5afd8,0\r\n",
      "00cc46aaa5c56e5021f0,0\r\n",
      "00cdfc5f5d70ee6c9a97,0\r\n",
      "00d110f9c41810272868,0\r\n",
      "00d2925dd74f0074a364,1\r\n",
      "00d2bdffa06ce7d88dce,0\r\n",
      "00d2bef0df771b0511d5,1\r\n",
      "00d567eb22ed18a24efd,0\r\n",
      "00d770cddb6ba30df967,0\r\n",
      "00d9194fedada40ca891,0\r\n",
      "00db5e6a1c73a0be9f16,0\r\n",
      "00db83cea2561cdf958f,0\r\n",
      "00dc4259284a151a293d,1\r\n",
      "00dd49fc7a54e696d34b,0\r\n",
      "00dd734c31ba5a44c7ff,0\r\n",
      "00e0091b00f07c7ab212,0\r\n",
      "00e08e70935dbc874017,0\r\n",
      "00e126b95ba90073e6cd,0\r\n",
      "00e224d307386ad35acc,0\r\n",
      "00e2b77d2c1aef9c398f,0\r\n",
      "00e2c830e82e72424db0,0\r\n",
      "00e3060ed0f4e1ef8417,0\r\n",
      "00e3998fff6d8a1bc707,0\r\n",
      "00e6714d2d71829e45d5,0\r\n",
      "00e6b59b91089d164990,0\r\n",
      "00e922f47f100ab1b747,0\r\n",
      "00ea502a32786ed1481d,0\r\n",
      "00ea5dc8e09307e986c7,0\r\n",
      "00eb7c589e72d82895cf,0\r\n",
      "00ebad9097d7dd9ad974,0\r\n",
      "00eedea3bbe8f8ebb97b,0\r\n",
      "00eef1e0df4664ed21ae,0\r\n",
      "00efa57670671f31d659,0\r\n",
      "00f0e703539b0a6216b7,0\r\n",
      "00f14f4d10f1965aefb4,0\r\n",
      "00f2a0c1b65c048e1e78,0\r\n",
      "00f856da4647af158d4a,0\r\n",
      "00fae51e4f5fe6adf7d8,0\r\n",
      "00fb0cc1efdc102c661f,1\r\n",
      "00fca416b244ac2ae6e4,0\r\n",
      "00fed32251f347c28697,0\r\n",
      "00ffc30b30ace96c74fc,0\r\n",
      "010096913ba53c3a2bd8,0\r\n",
      "0100b7284893f8602a1d,0\r\n",
      "0100f8e6c289ce7eb249,0\r\n",
      "0101e5ae3a3304c20593,0\r\n",
      "0103f015a3dff5b446cd,0\r\n",
      "0106dad562cdb2e1f532,0\r\n",
      "0107db3a3f6cb1a5edd4,0\r\n",
      "0107f71b25fdb896bd24,0\r\n",
      "010a8dddaa14a80b73c7,1\r\n",
      "010ad9ffda2ae84f1a5a,0\r\n",
      "010baeb06e79c553a1c0,0\r\n",
      "010dd44fb53d763272b6,0\r\n",
      "010de074db93470c327e,0\r\n",
      "011089901ddfb3f9a4da,0\r\n",
      "0110a76148ce9b9bf7c8,0\r\n",
      "011100f2faecfafcd6df,0\r\n",
      "01122578b3c9cbb32773,0\r\n",
      "0114eec3e5189bd1bbf5,1\r\n",
      "0116da27bf3264b4682d,0\r\n",
      "01183580de4815ec0353,0\r\n",
      "01185dcbba1e3d322395,0\r\n",
      "01185dec93733d86d57a,0\r\n",
      "0118e27cf03c4310e972,0\r\n",
      "011b310ecaa2500fd75c,0\r\n",
      "011c99955047e7c949d6,0\r\n",
      "011cb1fd8086dd55b4aa,0\r\n",
      "011cdaf40b8ce3450606,0\r\n",
      "012044f1825624a6044c,0\r\n",
      "0121fc6ee1adc8a4ecd5,0\r\n",
      "01221ef89884d5e478bb,0\r\n",
      "0122a4a6d475e3f312bf,0\r\n",
      "01256f56df069097dbc2,0\r\n",
      "012679d4a416b9c4dd1a,0\r\n",
      "012691e418f86472976b,0\r\n",
      "0127b87d75243a7dbf33,0\r\n",
      "01286131b91ed5199847,0\r\n",
      "01294e1a0fc88e9b5bc6,0\r\n",
      "012cce473c2245f4065b,0\r\n",
      "012fc2110f635daa7050,0\r\n",
      "0130906d01696b59f190,0\r\n",
      "0130a98dab4078e68ec7,0\r\n",
      "01338c72ac159903365d,0\r\n",
      "0135bc547ede7a40f502,0\r\n",
      "0135d2e0888fe9ea80a5,0\r\n",
      "0136829cd42a0e7b5aaa,0\r\n",
      "0137076332815c090fbd,0\r\n",
      "0139baf4392e73d548c0,0\r\n",
      "013ac13125102fb35e82,1\r\n",
      "013ce451075ad47c65e8,1\r\n",
      "013ec3258d14dfaa302d,1\r\n",
      "013f288ec47d2a4bb3b0,0\r\n",
      "01424ab27f2b35a3d7d7,0\r\n",
      "0146055209ba1c705203,0\r\n",
      "0146ff38bebf4776a80c,0\r\n",
      "01470403cac14d506587,0\r\n",
      "01478a4089e816a66b6b,0\r\n",
      "014822e8e346dd5f3087,0\r\n",
      "014bac886ce908d36860,0\r\n",
      "014c7250b9c301e51c84,0\r\n",
      "014c9611320628c6581c,0\r\n",
      "014f9e91cb369c8ebc15,0\r\n",
      "01504fec2ef5567e04f9,0\r\n",
      "0150a21f05ff10b39c5e,0\r\n",
      "015169ff904fac5aaf40,0\r\n",
      "0154f5f214795547c869,0\r\n",
      "01555d63324eec398e88,0\r\n",
      "0155f78ade4e3c58804f,0\r\n",
      "01576103208418cf66b8,0\r\n",
      "015785a599d0a031f085,0\r\n",
      "0158c8d9526a4d16bbda,0\r\n",
      "0159d63ddea2ae8892a5,0\r\n",
      "015c34ede0b3208d5d9d,0\r\n",
      "015c711ffb6aab65fed3,0\r\n",
      "015c74c9fc405409e192,0\r\n",
      "015cc0fb0205d758e561,0\r\n",
      "015d5e2a8485194efed7,0\r\n",
      "015d785b9d26d56b4ffe,0\r\n",
      "015e044ce7f3c1702bb9,0\r\n",
      "015e60c02ecec4d6bdd4,0\r\n",
      "0161e72b69582bb76bd0,0\r\n",
      "01635ae3b708816423ab,0\r\n",
      "0164f9d1417b271c27e2,0\r\n",
      "0165894435a98dbd50d1,0\r\n",
      "0165c415bf44e7992e20,0\r\n",
      "0165dd884530f94f69ce,0\r\n",
      "0166839212cf3a036b7e,0\r\n",
      "01669b731ba506acd760,0\r\n",
      "016859c5c11fbe77b990,0\r\n",
      "016921211bb4a14f304c,0\r\n",
      "01698abc6a00908bf650,0\r\n",
      "016ca1a9d1e3b1d2ed45,0\r\n",
      "016cd1f45c48fb91aae7,0\r\n",
      "016dc136c513426c8b64,0\r\n",
      "016dcd0ac3634376e6fa,0\r\n",
      "016e8f844e591ac2baba,0\r\n",
      "016eaf1d76c7a8a288b0,1\r\n",
      "016ed97f64449e8d79d4,0\r\n",
      "016f17002ea53bd37509,0\r\n",
      "017075752a9c4ab5d39c,0\r\n",
      "0172e171d30f5b600e0e,1\r\n",
      "0174186b22d5b786b4bc,0\r\n",
      "0174421f4ad997d08eb4,0\r\n",
      "01788ed3dea2981ee755,0\r\n",
      "017942509708e190685b,0\r\n",
      "017aaa959192a722f5d4,0\r\n",
      "017c083ae58691ce8e63,0\r\n",
      "017ce985054d2fe66524,0\r\n",
      "017de5a481095ea3416e,0\r\n",
      "0183eb15258f53e19289,0\r\n",
      "0186b8c5a18b3404ffa3,0\r\n",
      "0186cee71e404ebd452f,0\r\n",
      "01876f4cb76d9f04d844,0\r\n",
      "01891fab742b50e6b723,0\r\n",
      "018a88338251ea5fd95b,0\r\n",
      "018cf8d3e554887f014a,0\r\n",
      "018d75dda1c390dfe14c,0\r\n",
      "018dc0b7955e9abe30b1,0\r\n",
      "018e08adc3bf3030075e,0\r\n",
      "0190284236bc8ada8220,0\r\n",
      "0190d177b6bfa8c04377,0\r\n",
      "01923f5c087c1105e92d,0\r\n",
      "01929004c68d1d428464,1\r\n",
      "0192d4c50a099b88f545,0\r\n",
      "0193b7cc324de5508b56,0\r\n",
      "01947de9366534f8e583,0\r\n",
      "019656be61b471a0b424,0\r\n",
      "01965c3920939d74ed4b,0\r\n",
      "0196f2da78989e3a8fb3,1\r\n",
      "019715e14e8f5b2d9097,0\r\n",
      "019868d5e5a2980209d7,0\r\n",
      "0199091db4440417bf20,0\r\n",
      "019afb06d65263cf07fc,0\r\n",
      "019c2ce39fbaab532d48,0\r\n",
      "019c316abd4833969357,0\r\n",
      "019ee98a25584d56c1e7,0\r\n",
      "019fb2ce2d0882f50148,0\r\n",
      "01a2272dda5b6f73ae0e,0\r\n",
      "01a3b5c02b6eea8ebeca,1\r\n",
      "01a3d364f96abb79e178,0\r\n",
      "01a3d5fc08ee972ee1dd,0\r\n",
      "01a469838b0a24203000,0\r\n",
      "01a49ac2f30ad1f6e349,0\r\n",
      "01a537c9bf562b3ac3a6,0\r\n",
      "01a55f6368f237fc8401,1\r\n",
      "01a67c69c1a00f7f24ae,0\r\n",
      "01ad4ab2a62823f794d2,0\r\n",
      "01ae741f1dbb0b29e38e,0\r\n",
      "01b19137df64daadf91c,0\r\n",
      "01b276f22f669424c179,0\r\n",
      "01b519f2647a436f1ee7,0\r\n",
      "01b580ccd154e713bc84,0\r\n",
      "01b720767bdd3abe2695,0\r\n",
      "01b7603526d0efde4bcf,0\r\n",
      "01b7b8ce94f86253af6b,0\r\n",
      "01b8376c7c9d0fa7de68,0\r\n",
      "01b9c7da202c08daa7a5,0\r\n",
      "01bce9b813245d97fae6,0\r\n",
      "01bd52fe76115e5737e0,0\r\n",
      "01bdbcc22e105ee04bec,0\r\n",
      "01be8d3be850ed18c65b,0\r\n",
      "01bf1401a11b3a07d5c9,0\r\n",
      "01c14e356cbb82800f60,0\r\n",
      "01c1a75c527a718be446,0\r\n",
      "01c8256d07eaae403ed3,0\r\n",
      "01c883d35999624373a2,0\r\n",
      "01c9e1f4e01a2cb02d34,0\r\n",
      "01cc91302ad68545e7b4,0\r\n",
      "01cfcee917e96e0bd4ab,0\r\n",
      "01d0739ac2d4d71825ae,0\r\n",
      "01d0878856f0c06d26d3,0\r\n",
      "01d0aeffaa732fae745b,0\r\n",
      "01d0fb87c81a13bfb7b9,0\r\n",
      "01d24013ba9809e51d0d,0\r\n",
      "01d42ef399c1783e627a,0\r\n",
      "01d5622cd3dc08cc4da4,0\r\n",
      "01d7a1f1ea848d21f408,0\r\n",
      "01d8765a3a38349b27c9,0\r\n",
      "01d8777b8b4af1585bc6,0\r\n",
      "01da5a05e32422246fba,1\r\n",
      "01db38253dc39644133b,0\r\n",
      "01dc4dde4476effb0708,0\r\n",
      "01dfed3032e366128f00,0\r\n",
      "01e16cdbccecf40968e0,0\r\n",
      "01e19bbae954b8a3e71d,1\r\n",
      "01e3811873e5a99b75f2,0\r\n",
      "01e417b3264943642313,0\r\n",
      "01e553a15ad0d6e3d8f6,0\r\n",
      "01e728087034af305595,0\r\n",
      "01e89d64920bf7e2e2ba,0\r\n",
      "01eb13431fd6f20df889,0\r\n",
      "01ed902a198846f12dcd,1\r\n",
      "01ee53a900d058c11dde,0\r\n",
      "01ee8dda1833b47cfd0e,0\r\n",
      "01ef7eda61a228667467,0\r\n",
      "01f2ea457ab5fdde014f,0\r\n",
      "01f3adccba743d3f8ec7,0\r\n",
      "01f3c46028e5f3ff5ea5,0\r\n",
      "01f42166c8a61e55a49b,0\r\n",
      "01f5caf0cb8191a098e4,0\r\n",
      "01f5eb55866cbd8169b0,0\r\n",
      "01f7f6feb6e7d35fec09,1\r\n",
      "01f88ead073262b3a4ab,0\r\n",
      "01f89fab762f15f9ea9e,0\r\n",
      "01f8a4fe264642948ddf,0\r\n",
      "01fa24675253f9670d56,0\r\n",
      "01fadba05e44b2f2dc7b,0\r\n",
      "01fb308474c5f28bed2e,0\r\n",
      "01fb8e3357e20ae0289d,0\r\n",
      "01fbd5f50a92975e1120,0\r\n",
      "01fced5918ed67bcd82d,0\r\n",
      "01fe668c2da9bced4c8e,0\r\n",
      "01fe89ce2ed14134a130,1\r\n",
      "01ff613467e025bf744f,0\r\n",
      "02014dc79c7bfae48a9f,0\r\n",
      "0202a12ccb990e5767fb,0\r\n",
      "0202dfcc6e7361b33dac,1\r\n",
      "020439f3f1a31bbcb9e4,0\r\n",
      "0205b89fb2486b378c81,0\r\n",
      "0205ee1cd8c47fa1902b,0\r\n",
      "02063fef2e9581418a53,0\r\n",
      "0206892dab2f3f3adced,0\r\n",
      "020772dde8c7164bcea8,0\r\n",
      "0207be0072dbf1ac8932,0\r\n",
      "020a8e548876c99646fe,0\r\n",
      "020bda07a1f30a92859e,0\r\n",
      "020e553b99663be8e60f,0\r\n",
      "020f12ff4e7d22d5df12,0\r\n",
      "020f946e8412939f4df2,0\r\n",
      "02109d8434b872037efa,0\r\n",
      "021453119f6265598ad1,1\r\n",
      "02151b08d0cadd6031f1,0\r\n",
      "021595a5aca648423937,0\r\n",
      "021646b706aee5be78ca,0\r\n",
      "021790d11258095aff1d,0\r\n",
      "02187b9d05659a040bff,0\r\n",
      "02191c228e32e9d2bd13,0\r\n",
      "0219cfb71a36fb2b7984,0\r\n",
      "021b56348d887e2e61fa,0\r\n",
      "021e3f16ce9b26c17ec1,0\r\n",
      "021fde63feac3b8ddd4e,0\r\n",
      "02205936debeff1814e6,1\r\n",
      "0222f219011ec5f46d8b,0\r\n",
      "0223e5d22888b80509aa,0\r\n",
      "02250f5e7c1e5332af86,0\r\n",
      "022615fba847bd96f4e4,0\r\n",
      "02268e50a6e4a98b51c6,0\r\n",
      "02282f997d409a3d36e6,0\r\n",
      "022985510ec8d1846acd,0\r\n",
      "022a34385da9c139d785,0\r\n",
      "022aacc8a897346c2ae3,1\r\n",
      "022aef9f927a07e1d85a,0\r\n",
      "022c201826ab5165c371,0\r\n",
      "022cf487eeeb6d982c01,0\r\n",
      "022d289e9d3f68a75375,0\r\n",
      "022d54c083faa1a088cb,0\r\n",
      "022e7c913e7d03b8dee9,0\r\n",
      "02345313d44aab6698b5,0\r\n",
      "0235163a0d0e324a7ce7,0\r\n",
      "0235aa5bc74ecbb139a2,0\r\n",
      "0236bacbee8051a2124b,0\r\n",
      "02378ed0d52b6b0df664,0\r\n",
      "0238a95eca996326105f,0\r\n",
      "0239a348eb90c49e988c,0\r\n",
      "023bb85a09e5edc42cbb,1\r\n",
      "023e1b0eb9938ea2da5f,0\r\n",
      "023eceb7ac6fda2fe1a1,0\r\n",
      "023f5b777236778b1730,0\r\n",
      "023f9df6d23f5115e094,0\r\n",
      "02412ea921c9a862f82a,0\r\n",
      "02418c99ed4c8af8946a,0\r\n",
      "0243f79003ee3d0f79a8,0\r\n",
      "0245246fc347df9b1397,0\r\n",
      "02477b1f93cf0623c0ab,0\r\n",
      "02477f141ec63920712f,0\r\n",
      "024796098354275543ef,0\r\n",
      "0247a31f584a608e8780,0\r\n",
      "0247e5a9cd8addfadb77,0\r\n",
      "024b2aa8f955252fdce7,0\r\n",
      "024b5c1c6f0f96305b59,0\r\n",
      "024ba6b915b993c92d75,0\r\n",
      "024d7caa5a875c288269,0\r\n",
      "024e56487631af5459d4,0\r\n",
      "024ec12e488ea07d3fda,0\r\n",
      "024edd6b453dccbadca5,0\r\n",
      "025003e4785d51a145e5,0\r\n",
      "02504ec1fee601c55885,0\r\n",
      "025071dd083d2f251e13,0\r\n",
      "0254b8a2e9bb4ba86622,0\r\n",
      "0254e3eaa4a3b97f9df2,0\r\n",
      "0254ffd637973aa69d58,0\r\n",
      "02551f8457176e296558,0\r\n",
      "025652325322c3b7adf0,0\r\n",
      "0256ae7adc548e17f783,0\r\n",
      "025873505dc0fbd4253c,0\r\n",
      "0258d1d53837da585e08,0\r\n",
      "025913abd1c5b150ea4e,0\r\n",
      "025b09fd26bb72b50625,0\r\n",
      "025c7304c65eec0466d9,0\r\n",
      "025cc251234471387bac,0\r\n",
      "025cfb805411c1919e4b,0\r\n",
      "025dad80944b9bb96cca,0\r\n",
      "025e473ee43d9ce3160a,0\r\n",
      "025f8a484343597a362d,0\r\n",
      "0260b262b9c243684dfc,0\r\n",
      "02614a35c932e34540d7,0\r\n",
      "0262dd27a13dc6de46bc,0\r\n",
      "02642144b626372dd234,0\r\n",
      "0265813ad135be29ec82,0\r\n",
      "0267730ed8f326e2072e,0\r\n",
      "026799710a3079815b5e,1\r\n",
      "02686b5a9cccf6e40061,0\r\n",
      "0268c2570bc2c336abed,0\r\n",
      "0269555bf171fc17449a,0\r\n",
      "026b6e5012feffb5e1c7,0\r\n",
      "026c99bd9faacbc0a201,0\r\n",
      "026d1eadd67bff8fd833,0\r\n",
      "026d2c8177d4230353a4,0\r\n",
      "026d737149cb83860027,0\r\n",
      "026e007684abdad599c2,0\r\n",
      "026e1f2b2b863f362c64,0\r\n",
      "0271a3208e22cee246d1,0\r\n",
      "02731f5b2d7c1c314232,0\r\n",
      "0273a9ff5854b2abef26,0\r\n",
      "027471553cb9e0082423,0\r\n",
      "0275732c00da2138bf61,0\r\n",
      "02762b494db26a06e225,0\r\n",
      "0277ee00fa7db7862b5d,1\r\n",
      "02789881419d261396e4,1\r\n",
      "02796b28f78ad2863b81,0\r\n",
      "027ba30f29d164d54142,0\r\n",
      "027bc3be1e78cc9ed598,0\r\n",
      "027d25a48c2ecb976c82,1\r\n",
      "027e411a65af6de18d3a,0\r\n",
      "027ea8d12cb1f4f56f64,0\r\n",
      "027fe04471b03a1cfe52,0\r\n",
      "028166c9d8ddbe902314,0\r\n",
      "0281f6e1f03b85604c54,0\r\n",
      "0282091a8c2fba15bb58,0\r\n",
      "0283bfac102218a23a43,0\r\n",
      "02869b7a1ee565eebaf6,0\r\n",
      "0286aef5799a47344017,0\r\n",
      "028821da128ccf9cf972,0\r\n",
      "0288df19db22d1d08dfa,0\r\n",
      "02890eb2852815f83d90,0\r\n",
      "028971e32565f05392ad,0\r\n",
      "0289b166f13e14eaf698,0\r\n",
      "028b4db31f4533ba4c67,1\r\n",
      "028c2c119751af41d3ec,0\r\n",
      "028d02b319e45683ca09,0\r\n",
      "028f24eb528a77d46e89,0\r\n",
      "029267a43b14b92ca732,0\r\n",
      "0293751be124f6fe6116,0\r\n",
      "0294c1e5a636b69a898c,0\r\n",
      "02955b73552c30137387,0\r\n",
      "029598bf54d3b12ab1c8,1\r\n",
      "02964c4c6aaef4b7c273,0\r\n",
      "029a329bb10570938ce7,0\r\n",
      "029b3e40a9769a53fe1e,1\r\n",
      "029b919f9afe896791fe,0\r\n",
      "029be5ec714b76fab00e,0\r\n",
      "029c9f7300c867c326a9,0\r\n",
      "029ce5b534fa389d1908,0\r\n",
      "029eaf78586f7b17ebf8,0\r\n",
      "029ee54eff69425fbe16,0\r\n",
      "029f4f221adf18ede468,0\r\n",
      "029ffa0043963f269b23,0\r\n",
      "02a5387d2ed8ada961e9,0\r\n",
      "02a5f199597d21e4edfc,0\r\n",
      "02a6c51d8b6689c41fa6,0\r\n",
      "02a8d85e1594899061dd,0\r\n",
      "02a99804d0120d1f62f7,0\r\n",
      "02aa76fba3b0e589ceca,0\r\n",
      "02aa818067aa2e79c2e6,1\r\n",
      "02aae27784febe434a7a,0\r\n",
      "02ae71d8d8e567454e28,0\r\n",
      "02afa68660c841933b43,0\r\n",
      "02b1757ec7bb71de1b1d,1\r\n",
      "02b17be237f134379afb,0\r\n",
      "02b26690b21100fd3b6c,0\r\n",
      "02b3bf9af4a3f6c2838f,0\r\n",
      "02b46f27fd441f736ada,0\r\n",
      "02b6147b1b18196fc496,0\r\n",
      "02b7f5a401c447492da7,0\r\n",
      "02b9de88ff5f03a85f3c,0\r\n",
      "02bbd5479f684075aa03,0\r\n",
      "02bca4b6808c71632412,1\r\n",
      "02c04c110e3da164aacd,0\r\n",
      "02c1bad0875882936c63,0\r\n",
      "02c1ea7237a43fb5aa19,0\r\n",
      "02c2a574c47d3429ff89,0\r\n",
      "02c5f92a2965642577a5,0\r\n",
      "02c613d247ee074fc9dd,0\r\n",
      "02c74fd5316b4b4c3351,0\r\n",
      "02c7e142734004356e73,0\r\n",
      "02c830f58a62ba1c734c,0\r\n",
      "02c8ce1b284aac294d34,0\r\n",
      "02ccac2f51ad94c5fe7d,0\r\n",
      "02ccf946b5eb8b965e8f,0\r\n",
      "02ce3d13faa5d3670cb8,0\r\n",
      "02ce42bd077800e58312,0\r\n",
      "02d3e0db699bb3322e4d,0\r\n",
      "02d426c7142c0e4ea099,0\r\n",
      "02d42aeaad23a728a678,0\r\n",
      "02d74d4659b5ef0ebf9a,0\r\n",
      "02d879608e51719f7ab6,0\r\n",
      "02d8c72d89d512957384,0\r\n",
      "02d9799487c21be5ef1c,0\r\n",
      "02dbccda42f727a03e8e,1\r\n",
      "02dc020d4fae0f390834,0\r\n",
      "02dcaf0d0beac4dd09c1,0\r\n",
      "02dcc77293ec0645e4c0,0\r\n",
      "02de0d900e04d9a14b91,0\r\n",
      "02e2316b85a17594dc4b,0\r\n",
      "02e4bf0c33e4efe91a51,0\r\n",
      "02e7d0827db806ee6f68,0\r\n",
      "02e9372f62c9a610983e,0\r\n",
      "02ea1613cafb22d11f5c,0\r\n",
      "02eb15538cc47654c64b,0\r\n",
      "02eb4dd63d09177acac5,0\r\n",
      "02edfcb02312e3fd5508,0\r\n",
      "02ee33a99dd2c1e0216d,0\r\n",
      "02eef8e7af2c1efba408,0\r\n",
      "02efc89f52956c44ec08,0\r\n",
      "02f128768d1c46a421ed,0\r\n",
      "02f35c0f64cbeb6cd69b,0\r\n",
      "02f35c943224fb9856ad,0\r\n",
      "02f3d14e62f966271ed7,0\r\n",
      "02f4138d782556c2ac33,0\r\n",
      "02f43c4c2ea82de54978,0\r\n",
      "02f693770fbd870d34bb,0\r\n",
      "02f6a5965da5a57eafd3,0\r\n",
      "02f7e7122f38f05204b2,0\r\n",
      "02f95c3894fe9de24310,0\r\n",
      "02f9c5b68a3a0b052dc5,0\r\n",
      "02faba345a9256c5d743,0\r\n",
      "02fb8278741238133c56,0\r\n",
      "02fc110fd08c936470bc,0\r\n",
      "03013d04cf4ff248ad70,0\r\n",
      "030258391a6435b58e8d,0\r\n",
      "0302e054ecd2fdb11dec,0\r\n",
      "03039ba7aaa490b30463,1\r\n",
      "0303edacca3a8c4707c5,0\r\n",
      "03046ce456e70a6bb089,0\r\n",
      "0305fa96fa281ab55627,0\r\n",
      "03070d2b5dcce34dffbd,0\r\n",
      "0307be90c26c9245fcd1,0\r\n",
      "03082265e3e6a9c486ab,0\r\n",
      "030973015356c97249b1,0\r\n",
      "0309af93a1a005ba1e86,0\r\n",
      "030b150de4234d13f589,0\r\n",
      "030c337c01e886b888d7,0\r\n",
      "030f7e707a0cd8c1387a,0\r\n",
      "030fc27e81c4fc83bd1e,0\r\n",
      "03139c5eaf5d981da043,0\r\n",
      "0313f50a7fd45382ce16,0\r\n",
      "03153a6e27ef04b60e9f,0\r\n",
      "03154f85d07343b2ae0e,0\r\n",
      "03162657b14d2de04818,0\r\n",
      "0317e5e957c3689b8356,0\r\n",
      "031a3c49a3513b2f55c8,0\r\n",
      "031b04dba5dc55e8b6d2,0\r\n",
      "031b35b3e181137c4b98,0\r\n",
      "031bb89d27ba62070d05,0\r\n",
      "031d7af6c7bd6d1bd2a5,0\r\n",
      "031fb52635b65bcfab53,0\r\n",
      "03215bb4b4e889bbb805,0\r\n",
      "03267e5c13cfcb2cc3ba,0\r\n",
      "032755eeac154112d3af,0\r\n",
      "0329235dbfddbab38837,0\r\n",
      "0329c2ef3473252ba9ae,0\r\n",
      "0329f21123963029b42a,1\r\n",
      "032b7c97cc3df41f827f,0\r\n",
      "032c1852080fee04c4d0,0\r\n",
      "032d9430bacb8391642c,0\r\n",
      "032fa3ed5e43d22a4537,0\r\n",
      "032fc51493f1a7f104ad,0\r\n",
      "03305791f463c2bdd475,0\r\n",
      "0330dcd08abcd725059b,0\r\n",
      "0332d19fd5412370e9df,0\r\n",
      "0333a6c2f7745f3398c2,0\r\n",
      "0334868b95aedbd1a8b5,0\r\n",
      "0334ed997a0fdc6223e3,0\r\n",
      "033548b404df940e9fff,0\r\n",
      "03359bd9741282cf6bc1,0\r\n",
      "0335ad623e785a9cb842,0\r\n",
      "0338b34edabdfabdd69f,0\r\n",
      "0339038ea050868d3c97,0\r\n",
      "03390a8d2ff2ca50e1e8,0\r\n",
      "03395f89b5f0dd7b2a38,0\r\n",
      "033b9ef01da9146d36a9,0\r\n",
      "033cd10f531d247798ec,0\r\n",
      "033dd34d82964b6ac7da,0\r\n",
      "033f6f136172ca0699b9,0\r\n",
      "034188b140550acef19a,0\r\n",
      "0343040b2b9248256be4,0\r\n",
      "034492506030e0b30b54,0\r\n",
      "03468fa82d27c2a9b34f,0\r\n",
      "0348ec02fe4eb0c45a75,0\r\n",
      "034943dcab89cc216f08,0\r\n",
      "034b11c7ec22f81c8f61,0\r\n",
      "034b7df75d89ab56287a,0\r\n",
      "034b8d5d95f894d73c20,0\r\n",
      "034c0efe6eae686b51f2,1\r\n",
      "034c5cf73d72e667eb2b,0\r\n",
      "034d815903b848a2b54e,0\r\n",
      "034f01061dc2dbe50b29,0\r\n",
      "0350b1ce1fc3d65394a1,0\r\n",
      "0350bf780d7bb9f39b37,0\r\n",
      "0350c981b72c9159c875,0\r\n",
      "0352545531730466877f,0\r\n",
      "0352e3dc3f100103131b,0\r\n",
      "0352eb6a053f5ea9bc45,0\r\n",
      "0352f0029a1ff4fcf1fa,0\r\n",
      "0353df5ea44fc7fb382e,0\r\n",
      "0356133ae2dd8fcef112,0\r\n",
      "03561dd167c5629eea29,0\r\n",
      "03597ff31c7be88cc2d1,0\r\n",
      "035a4ab5bf5ab9f2e000,0\r\n",
      "035bd74a7eca42b0008f,0\r\n",
      "035ca5cfe89019bc22a6,0\r\n",
      "035d35230479d19837ae,0\r\n",
      "035deab7184bca5bbad3,0\r\n",
      "035e8dd08e4b1e9ffa00,0\r\n",
      "035efe0642dc043c7dfc,0\r\n",
      "035f2abb0a8e87abdf53,0\r\n",
      "03628d61e19372b4f3cc,0\r\n",
      "0364045dd5792f7f8084,1\r\n",
      "0364ded1754827760757,0\r\n",
      "0365b551088a19aa39e6,0\r\n",
      "0365b7483a493ae08c9c,1\r\n",
      "036802b7b71b86291b71,0\r\n",
      "0369985900b2b7bda377,0\r\n",
      "036c2fc8ea61dcc4b805,0\r\n",
      "036c3f6ac98a5a682fb3,0\r\n",
      "036f23df38a5130781a3,1\r\n",
      "037388d70823c9bed8a7,0\r\n",
      "0374419b697926753b80,0\r\n",
      "0375d67ef5a4fc02c5e7,0\r\n",
      "0376257e6e6fec2c5185,0\r\n",
      "037bd3474eb123332fc8,0\r\n",
      "037be53248c4dee4a26b,0\r\n",
      "037bf80e894ae1e928d2,0\r\n",
      "037d0bc65f892d21f028,0\r\n",
      "037d314e2ecc93f555b6,0\r\n",
      "037f3a2577b9e21deddb,0\r\n",
      "037f7e87e151cb90a7c3,0\r\n",
      "03812e8d01e506bd0892,1\r\n",
      "038208dfcd7aafe57cf0,0\r\n",
      "03821f6053f3bc24287b,0\r\n",
      "03830c7b4467b03da803,0\r\n",
      "0384c34894fa4ba19153,0\r\n",
      "03854a7fb7109c7cc59e,0\r\n",
      "0386ae2a6d040e4ab29a,0\r\n",
      "038731afbb68d5f9cff9,0\r\n",
      "03876bf53c308ce06388,0\r\n",
      "03899b07b3565ccccce4,0\r\n",
      "0389fd7d87dd3e7a4ced,0\r\n",
      "038b1f91dc59286fb21d,0\r\n",
      "038f45ebd6320ab7968e,0\r\n",
      "039041f70bddf5b908ca,0\r\n",
      "0391497db4369dcf3355,0\r\n",
      "039240d6887f79ec5b4d,0\r\n",
      "039305394dc8686cf5f5,0\r\n",
      "039322963efce02eb2fd,0\r\n",
      "03944232c1acaeab6acb,0\r\n",
      "0394b20f97a497181b8c,0\r\n",
      "03950eb3a25b1e776913,0\r\n",
      "0395ef8bcd95efa5b9a4,0\r\n",
      "0397c0f0c85bf9eb4b99,0\r\n",
      "0398521a4c139338a96d,0\r\n",
      "03993a9b3a40de475495,0\r\n",
      "0399fd3a81872c6a5a8e,0\r\n",
      "039c6097f375fbef79a1,0\r\n",
      "039e726aa4f4e101fe82,0\r\n",
      "039f48d303422cecce08,0\r\n",
      "039faf2692bc150949ec,0\r\n",
      "03a28b6ab8d3a2dbad06,0\r\n",
      "03a700ab0e5f0b059970,0\r\n",
      "03a71f46b83ab5419328,0\r\n",
      "03a7f17123b8f9a6d286,0\r\n",
      "03a980027d6680410a72,0\r\n",
      "03aa3148dfebb5df67c7,0\r\n",
      "03aa8f5711270be56379,0\r\n",
      "03abb44cec5d21010287,0\r\n",
      "03ac48965d5f739ce457,0\r\n",
      "03ac60c6a333bf3d0e93,0\r\n",
      "03ae2201baeaa8ff1ec3,0\r\n",
      "03aed4bda0bc5fb14447,0\r\n",
      "03af9e4c4a8d6513f4ff,0\r\n",
      "03b03e3eabd2a656417f,0\r\n",
      "03b15486cec82ab5f2d8,0\r\n",
      "03b1f760cde475183759,0\r\n",
      "03b265eb951d154ebf6c,0\r\n",
      "03b267ad640f0bff525e,0\r\n",
      "03b45eba2a481653b7ee,0\r\n",
      "03b5aeafda6c4469aff1,0\r\n",
      "03b75dc9e70e69a29680,0\r\n",
      "03b907d48d3958125fb8,0\r\n",
      "03b973bbc3621a44570d,0\r\n",
      "03bb3e61e1af07d69cc6,0\r\n",
      "03bbd2f90b4c54982780,0\r\n",
      "03bbe7d049f3b5dc416c,0\r\n",
      "03bc9fe648414c22a9da,0\r\n",
      "03bcbe95ed4621fde9f9,0\r\n",
      "03bce0d20def484a1330,0\r\n",
      "03bdde31d2f4b53955ca,0\r\n",
      "03bf67b343f0e851a352,1\r\n",
      "03c1dc1f8b516875093d,0\r\n",
      "03c4a3c6719af62f2c0c,0\r\n",
      "03c572d59c3536fb76e2,0\r\n",
      "03c661605ba5d79fa664,0\r\n",
      "03c775b207879cc68063,0\r\n",
      "03c8529d57bdbcb88f1e,0\r\n",
      "03c8fd6105f22812eb46,0\r\n",
      "03c9d88b01d7de76d5c5,0\r\n",
      "03c9e1b344ed8eef1d5f,0\r\n",
      "03ca1aee9826159a946e,0\r\n",
      "03cb3d1fea4e736826ef,0\r\n",
      "03cc8a30cbb9161ef9cd,0\r\n",
      "03ccee66a22e72a500bd,0\r\n",
      "03ce4d9152b67d6f32c0,0\r\n",
      "03cedd5433304777b845,0\r\n",
      "03d03739f8d96dadd886,0\r\n",
      "03d0ef3afb582800e68c,0\r\n",
      "03d16b9962d84d147ab3,0\r\n",
      "03d20b44e018a0dd7874,0\r\n",
      "03d61bc064f0492a5013,0\r\n",
      "03d61f695d6f7d0eb71e,0\r\n",
      "03da154a0333c1142fde,0\r\n",
      "03da63444d75303c2fb2,0\r\n",
      "03de9d443860575915cd,0\r\n",
      "03e2e2419b5f742d6453,0\r\n",
      "03e42035bcbe992e9bb7,0\r\n",
      "03e544fa815463e2318b,0\r\n",
      "03e6ce64f3156f7cf52f,0\r\n",
      "03e733355b63435f73f6,0\r\n",
      "03e7bf35382c604cb334,0\r\n",
      "03e89fc0650a5d80b5ec,0\r\n",
      "03e9172283c7221e2345,0\r\n",
      "03e9b8a3463a3c16408e,0\r\n",
      "03ea459f2f6b7132413a,0\r\n",
      "03ea84e1291e0fd5d5ec,0\r\n",
      "03eaa5afb42be2752b6a,0\r\n",
      "03ec8fb7e4ec107fd8ad,0\r\n",
      "03ed2577c05209ea0e03,0\r\n",
      "03edd0c5819881bdf5e5,0\r\n",
      "03ef6389207a74fee05f,1\r\n",
      "03f133c984bcc4e34f8e,0\r\n",
      "03f3fb49a2f9a3012daf,0\r\n",
      "03f52993396271de3bc4,0\r\n",
      "03f6024000cbf379b046,1\r\n",
      "03f67b684aba002c3cb2,0\r\n",
      "03f70283d1421f719820,0\r\n",
      "03f8f0181dc229df31f5,0\r\n",
      "03f9722d79bc7dbf3b7a,0\r\n",
      "03fb3fd21c90da324e99,0\r\n",
      "03fcd9ce7142141e7932,0\r\n",
      "04006e238c9f94ba5c01,0\r\n",
      "0400bd7d8a38b933b52f,1\r\n",
      "0400c8b8505bbf9c8859,0\r\n",
      "04049cefb617ec069b4b,0\r\n",
      "040567566349d60783eb,0\r\n",
      "0407c1b6c08fb6b9c37e,0\r\n",
      "040d39c8c30fb53ac1fc,1\r\n",
      "040e0f75618ec3ecbc30,0\r\n",
      "040ed40da8c631aab4a6,0\r\n",
      "04102791c11742cfaaac,0\r\n",
      "0412160bd0af60d2833b,0\r\n",
      "04123b31410f437e8002,0\r\n",
      "041275989e5db3b5b33f,0\r\n",
      "0412c42e9cd2cedd15cd,0\r\n",
      "0414086982adac4dfc39,0\r\n",
      "0414bda36bd2112bada5,0\r\n",
      "04163ce0c51c8e52d62a,0\r\n",
      "041830d7f6fc59ccaeda,0\r\n",
      "041d657d53e52950cfc5,0\r\n",
      "0422a06bba90d5e2e8d5,0\r\n",
      "04247bfaa3a98ca03a4e,0\r\n",
      "04256cca3833bd7df362,0\r\n",
      "0425923806574b9e26a4,0\r\n",
      "0425a7c6569d0852b0f2,0\r\n",
      "04263590db576723897c,0\r\n",
      "0426c81a27cc4b276f22,0\r\n",
      "04276317bdcc577295eb,0\r\n",
      "042abbc1f7168d2dffaa,0\r\n",
      "042d8b6b9b5415094fc6,0\r\n",
      "042db03fc1f4478d2140,0\r\n",
      "042ea6bc94a45e4f085b,0\r\n",
      "042ec369c38c0b8a742d,0\r\n",
      "042f2dbd9d35d8b278cf,0\r\n",
      "0430f04b37c5e18385c3,0\r\n",
      "043188e03d04f0a1abda,0\r\n",
      "0431b8fcd5ec5f021a7c,0\r\n",
      "0431d580eaadac3ac6b6,0\r\n",
      "0433e6ee2c1171f3a419,0\r\n",
      "04359d00a698138880c7,0\r\n",
      "04364469734b6593f355,0\r\n",
      "0438a594c34ec01e1802,0\r\n",
      "043cd58395bc5eb8d0f3,0\r\n",
      "043d9d08d48d7dac13fb,0\r\n",
      "043decaac765e5aa89eb,0\r\n",
      "043e61b45feb1f9d5a64,0\r\n",
      "044175d46b53f1054377,0\r\n",
      "04428a0722dc19d1ad1d,0\r\n",
      "044386658509e1d3c298,0\r\n",
      "044404e1c258d8cc96d2,0\r\n",
      "044444d0891297b74713,0\r\n",
      "044499126031fafb352a,0\r\n",
      "0446d1ee7667eefbf295,0\r\n",
      "0448197ca87b188797e1,0\r\n",
      "0448c78834b16d6fc474,0\r\n",
      "044ba64de256383572db,0\r\n",
      "044c11b5e0791c3b1101,0\r\n",
      "044d6aea041bead8836e,1\r\n",
      "044e17b15cd1bcc65d9f,0\r\n",
      "044e9cb61c339b6ade6a,0\r\n",
      "044ed85bf160a6c9da75,0\r\n",
      "044f1edf586185ba834c,0\r\n",
      "0452882cde903b375e01,0\r\n",
      "0452f1b84166e5055243,0\r\n",
      "04552175544c3928a188,0\r\n",
      "0457e59db06dad8d4fd3,0\r\n",
      "0457ed7cd0fa9f180bc5,0\r\n",
      "04588e6d06b3e1b10101,0\r\n",
      "0459e766c4f4b5e80bfa,0\r\n",
      "0459f7c559f2621d5cd8,0\r\n",
      "045b58800c448f540594,0\r\n",
      "045c0d6171b5b29bd3e1,0\r\n",
      "045ce0e82192ab0e3548,0\r\n",
      "045d7c4a68e5dc1adc13,0\r\n",
      "045d820d62f8f34e2323,0\r\n",
      "045eab64de521e5b7394,0\r\n",
      "045f155100816f0bcf6c,1\r\n",
      "045fc32856d5db9a20b9,0\r\n",
      "04609fe113b9bc1ae16d,0\r\n",
      "04619b03b19c0b7513ea,0\r\n",
      "04622b65924fe7dd873b,0\r\n",
      "04630d5cac8588f12cd0,0\r\n",
      "0463cf98bf2bd9afd5dc,0\r\n",
      "0464b9a7b883a2088d33,0\r\n",
      "0465e7c22f5bc867a9a2,0\r\n",
      "0466ef9ed5ae0d6a8800,0\r\n",
      "046846f7ae17c76d2117,0\r\n",
      "04685c4b8201e8152be9,0\r\n",
      "0469149f1705b1426252,0\r\n",
      "046d11c669eb61d68ea0,0\r\n",
      "046d4efacb9246105767,0\r\n",
      "046d58fbac3ea06aa152,0\r\n",
      "046d86201e475df70076,0\r\n",
      "046dec211834a93706c4,0\r\n",
      "046fdd568083a56e2132,0\r\n",
      "04716df80bff2f89ea7d,0\r\n",
      "04730a801a566752425d,0\r\n",
      "0474dee41c5f8d2efb9f,0\r\n",
      "0475a0bbd3589145192b,0\r\n",
      "0475db396d3bf698e2dc,0\r\n",
      "0477f6b8af2f3e7b71ec,0\r\n",
      "04784b6af0921d36a781,0\r\n",
      "047ca3941427868d2d1a,0\r\n",
      "047d10b14b15641fa97a,0\r\n",
      "047d2b09445d97009240,0\r\n",
      "047d4a9b1936303d5be8,0\r\n",
      "047d9c12d748aedf38f4,0\r\n",
      "047f7205226361840b48,0\r\n",
      "047fb804da530af418aa,0\r\n",
      "048247d94722d487f08f,0\r\n",
      "048282f595ae595116c4,0\r\n",
      "0482d1274d0f59f6b7bf,0\r\n",
      "0484fb103b03f1049f38,0\r\n",
      "04878bfdf64c27044848,0\r\n",
      "04889bbe039d0cbbe29b,0\r\n",
      "0489231de918cf0d9939,0\r\n",
      "0489c4cecb35834d3699,0\r\n",
      "0489f707c5a44044e2ee,0\r\n",
      "048a4aedad9e76dd3554,0\r\n",
      "048b0d18e812c458f683,0\r\n",
      "048b37d2421d2432be5b,0\r\n",
      "048d6680ff9b8cd4fbbc,0\r\n",
      "048d8bf36cec597ca559,0\r\n",
      "048d915ca201d536f2ed,0\r\n",
      "049055b665204a7ab9f9,0\r\n",
      "04906d0c2407eecd6e2b,0\r\n",
      "0494166d813597c0954b,0\r\n",
      "0494cf5e254ff6e605a5,1\r\n",
      "04972f1414ea7b75b302,0\r\n",
      "0497569476ee78ac3462,0\r\n",
      "049a709c6e5f8cef8a39,0\r\n",
      "049b866a408fdf625945,0\r\n",
      "049becbaf67512dd88d9,0\r\n",
      "049c6aa6e914d629fea3,0\r\n",
      "049d4391cb28bd3eabb1,0\r\n",
      "049e04c1edd05d92acc9,0\r\n",
      "049e235c0a706549e805,0\r\n",
      "049f1fdc9bcd648031ef,0\r\n",
      "04a11700ec3447077bb1,0\r\n",
      "04a3fc263cbba5c269ab,0\r\n",
      "04a4e2ea40f3da29e5ed,0\r\n"
     ]
    }
   ],
   "source": [
    "!head -1000 submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f63cda14397adf5dc91a12363c1092a6f3c93543"
   },
   "source": [
    "### References\n",
    "\n",
    "- Discussion on 3rd Place winner model in Toxic comment: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52644\n",
    "- 3rd Place model in Keras by Larry Freeman - https://www.kaggle.com/larryfreeman/toxic-comments-code-for-alexander-s-9872-model\n",
    "- Pytorch starter Capsule model: https://www.kaggle.com/spirosrap/bilstm-attention-kfold-clr-extra-features-capsule\n",
    "- How to: Preprocessing when using embeddings https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings\n",
    "- Improve your Score with some Text Preprocessing https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing\n",
    "- https://www.kaggle.com/ziliwang/baseline-pytorch-bilstm\n",
    "- https://www.kaggle.com/hengzheng/pytorch-starter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
